{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Generates mlpModel\n",
    "import onnxruntime as rt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import wilcoxon\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from testing import *\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import onnxruntime as rt\n",
    "import onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import convert_sklearn\n",
    "\n",
    "data = pd.read_csv('data/investigation_train_large_checked.csv')\n",
    "y = data['checked']\n",
    "X = data.drop(['checked', 'Ja', 'Nee'], axis=1)\n",
    "X = X.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Preprocessing\n",
    "numeric_features = list(range(X.shape[1]))  # assuming all features are numeric in make_classification\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Combine preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipelines for both models\n",
    "mlp_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", MLPClassifier(hidden_layer_sizes=(16,8),  \n",
    "                    activation='relu',            \n",
    "                    solver='adam',                \n",
    "                    max_iter=100,                \n",
    "                    random_state=42,\n",
    "                    verbose=True))\n",
    "])\n",
    "\n",
    "# Train both models on full training data\n",
    "mlp_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Let's convert the model to ONNX\n",
    "onnx_model = convert_sklearn(\n",
    "    mlp_pipeline, initial_types=[('X', FloatTensorType((None, X.shape[1])))],\n",
    "    target_opset=12)\n",
    "\n",
    "# How to get metrics such as accuracy\n",
    "sess = rt.InferenceSession(onnx_model.SerializeToString())\n",
    "y_pred_onnx =  sess.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "y_pred_onnx_binary = pred_to_binary(y_pred_onnx[0]) # Do not forget\n",
    "y_test = y_test.astype(int) # Do not forget\n",
    "accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx_binary)\n",
    "\n",
    "print('Accuracy of the ONNX model: ', accuracy_onnx_model)\n",
    "\n",
    "# Let's save the model\n",
    "onnx.save(onnx_model, \"model/mlpmodel.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Gemerates Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import onnxruntime as rt\n",
    "import onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skl2onnx import convert_sklearn\n",
    "from goodModel import change_labels_data_augmentation_binary, data_augmentation_age\n",
    "from sklearn.model_selection import train_test_split\n",
    "import testing\n",
    "\n",
    "def modify_data(df):\n",
    "    df = change_labels_data_augmentation_binary(df, 'persoon_geslacht_vrouw')\n",
    "    df = data_augmentation_age(df)\n",
    "    #df = goodModel.drop_personality_columns(df)\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv('data/investigation_train_large_checked.csv')\n",
    "data = modify_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_to_binary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 36\u001B[0m\n\u001B[1;32m     34\u001B[0m sess \u001B[38;5;241m=\u001B[39m rt\u001B[38;5;241m.\u001B[39mInferenceSession(onnx_model\u001B[38;5;241m.\u001B[39mSerializeToString())\n\u001B[1;32m     35\u001B[0m y_pred_onnx \u001B[38;5;241m=\u001B[39m  sess\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;28;01mNone\u001B[39;00m, {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m'\u001B[39m: X_test\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mfloat32)})\n\u001B[0;32m---> 36\u001B[0m y_pred_onnx_binary \u001B[38;5;241m=\u001B[39m \u001B[43mpred_to_binary\u001B[49m(y_pred_onnx[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;66;03m# Do not forget\u001B[39;00m\n\u001B[1;32m     37\u001B[0m y_test \u001B[38;5;241m=\u001B[39m y_test\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m) \u001B[38;5;66;03m# Do not forget\u001B[39;00m\n\u001B[1;32m     38\u001B[0m accuracy_onnx_model \u001B[38;5;241m=\u001B[39m accuracy_score(y_test, y_pred_onnx_binary)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pred_to_binary' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's specify the features and the target\n",
    "y = data['checked']\n",
    "X = data.drop(['checked', 'Ja', 'Nee'], axis=1)\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Preprocessing\n",
    "numeric_features = list(range(X.shape[1]))  # assuming all features are numeric in make_classification\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Combine preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipelines for both models\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42))\n",
    "])\n",
    "\n",
    "# Train both models on full training data\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Let's convert the model to ONNX\n",
    "onnx_model = convert_sklearn(\n",
    "    rf_pipeline, initial_types=[('X', FloatTensorType((None, X.shape[1])))],\n",
    "    target_opset=12)\n",
    "\n",
    "# How to get metrics such as accuracy\n",
    "sess = rt.InferenceSession(onnx_model.SerializeToString())\n",
    "y_pred_onnx =  sess.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "y_pred_onnx_binary = pred_to_binary(y_pred_onnx[0]) # Do not forget\n",
    "y_test = y_test.astype(int) # Do not forget\n",
    "accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx_binary)\n",
    "\n",
    "print('Accuracy of the ONNX model: ', accuracy_onnx_model)\n",
    "\n",
    "# Let's save the model\n",
    "onnx.save(onnx_model, \"model/RFmodel.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aitesting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}