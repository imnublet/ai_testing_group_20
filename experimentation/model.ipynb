{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2d0b106-f3e0-4936-baff-d178197bc36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import onnxruntime as rt\n",
    "import onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes\n",
    "from skl2onnx.common._apply_operation import apply_add\n",
    "from skl2onnx import to_onnx\n",
    "from skl2onnx import convert_sklearn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d89819-2794-444d-8350-d4e51d1613d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_desc = pd.read_csv('data/data_description.csv', encoding='latin-1')\n",
    "df = pd.read_csv('data/investigation_train_large_checked.csv')\n",
    "df_synth = pd.read_csv('data/synth_data_for_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a7d8817-1899-4187-b820-6b0e83e78b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = df.drop(columns=['checked', 'Ja', 'Nee'])\n",
    "# Labels\n",
    "y = df['checked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18bd7fa0-cc7a-4614-89ae-83690113f521",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLPClassifier(hidden_layer_sizes=(16,8),  \n",
    "                    activation='relu',            \n",
    "                    solver='adam',                \n",
    "                    max_iter=10,                \n",
    "                    random_state=42,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ad7ba1d-ad88-4d7c-a456-d931f73ce31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.32641634\n",
      "Iteration 2, loss = 0.22215839\n",
      "Iteration 3, loss = 0.20047043\n",
      "Iteration 4, loss = 0.18707304\n",
      "Iteration 5, loss = 0.17587563\n",
      "Iteration 6, loss = 0.16680324\n",
      "Iteration 7, loss = 0.16024601\n",
      "Iteration 8, loss = 0.15358594\n",
      "Iteration 9, loss = 0.14810107\n",
      "Iteration 10, loss = 0.14370271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sayf/miniconda3/envs/ai_test/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.32411397\n",
      "Iteration 2, loss = 0.21903978\n",
      "Iteration 3, loss = 0.19769433\n",
      "Iteration 4, loss = 0.18443786\n",
      "Iteration 5, loss = 0.17405713\n",
      "Iteration 6, loss = 0.16458343\n",
      "Iteration 7, loss = 0.15766025\n",
      "Iteration 8, loss = 0.15075948\n",
      "Iteration 9, loss = 0.14494376\n",
      "Iteration 10, loss = 0.14057842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sayf/miniconda3/envs/ai_test/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.32720633\n",
      "Iteration 2, loss = 0.22290176\n",
      "Iteration 3, loss = 0.20149265\n",
      "Iteration 4, loss = 0.18899317\n",
      "Iteration 5, loss = 0.17805663\n",
      "Iteration 6, loss = 0.16889629\n",
      "Iteration 7, loss = 0.16188729\n",
      "Iteration 8, loss = 0.15520315\n",
      "Iteration 9, loss = 0.14965224\n",
      "Iteration 10, loss = 0.14510542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sayf/miniconda3/envs/ai_test/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.32552575\n",
      "Iteration 2, loss = 0.22082271\n",
      "Iteration 3, loss = 0.19996688\n",
      "Iteration 4, loss = 0.18751979\n",
      "Iteration 5, loss = 0.17758120\n",
      "Iteration 6, loss = 0.16928746\n",
      "Iteration 7, loss = 0.16222364\n",
      "Iteration 8, loss = 0.15668896\n",
      "Iteration 9, loss = 0.15100659\n",
      "Iteration 10, loss = 0.14659050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sayf/miniconda3/envs/ai_test/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.32545055\n",
      "Iteration 2, loss = 0.22202852\n",
      "Iteration 3, loss = 0.20045559\n",
      "Iteration 4, loss = 0.18787874\n",
      "Iteration 5, loss = 0.17782910\n",
      "Iteration 6, loss = 0.16994870\n",
      "Iteration 7, loss = 0.16209580\n",
      "Iteration 8, loss = 0.15606860\n",
      "Iteration 9, loss = 0.15064169\n",
      "Iteration 10, loss = 0.14582912\n",
      "Logistic Regression CV Accuracy: 0.9167 ± 0.0024\n",
      "Gradient Boosting CV Accuracy: 0.9241 ± 0.0009\n",
      "MLP CV Accuracy: 0.9241 ± 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sayf/miniconda3/envs/ai_test/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.30823164\n",
      "Iteration 2, loss = 0.21451078\n",
      "Iteration 3, loss = 0.19460488\n",
      "Iteration 4, loss = 0.18233298\n",
      "Iteration 5, loss = 0.17180304\n",
      "Iteration 6, loss = 0.16333488\n",
      "Iteration 7, loss = 0.15622752\n",
      "Iteration 8, loss = 0.15042989\n",
      "Iteration 9, loss = 0.14571517\n",
      "Iteration 10, loss = 0.14134330\n",
      "Logistic Regression Test Accuracy: 0.9147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sayf/miniconda3/envs/ai_test/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Test Accuracy: 0.9237\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Preprocessing\n",
    "numeric_features = list(range(X.shape[1]))  # assuming all features are numeric in make_classification\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Combine preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipelines for both models\n",
    "logreg_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "gb_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "mlp_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", mlp_model)\n",
    "])\n",
    "\n",
    "# Cross-validation scores for Logistic Regression\n",
    "logreg_scores = cross_val_score(logreg_pipeline, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "# Cross-validation scores for Gradient Boosting\n",
    "gb_scores = cross_val_score(gb_pipeline, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "# Cross-validation scores for Gradient Boosting\n",
    "mlp_scores = cross_val_score(mlp_pipeline, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "print(f\"Logistic Regression CV Accuracy: {logreg_scores.mean():.4f} ± {logreg_scores.std():.4f}\")\n",
    "print(f\"Gradient Boosting CV Accuracy: {gb_scores.mean():.4f} ± {gb_scores.std():.4f}\")\n",
    "print(f\"MLP CV Accuracy: {gb_scores.mean():.4f} ± {gb_scores.std():.4f}\")\n",
    "\n",
    "\n",
    "# Train both models on full training data\n",
    "logreg_pipeline.fit(X_train, y_train)\n",
    "gb_pipeline.fit(X_train, y_train)\n",
    "mlp_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Test accuracy\n",
    "print(f\"Logistic Regression Test Accuracy: {logreg_pipeline.score(X_test, y_test):.4f}\")\n",
    "print(f\"Gradient Boosting Test Accuracy: {gb_pipeline.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65d94950-7e2a-416d-863f-c52ab3d4b543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input name: float_input, Output name: output_label\n",
      "Accuracy of the ONNX model:  0.9258461538461539\n"
     ]
    }
   ],
   "source": [
    "# Convert the sklearn pipeline to ONNX\n",
    "input_features = X_train.shape[1]\n",
    "initial_type = [('float_input', FloatTensorType([None, input_features]))]\n",
    "\n",
    "onnx_model = convert_sklearn(\n",
    "    mlp_pipeline, initial_types=initial_type,\n",
    "    target_opset=12\n",
    ")\n",
    "\n",
    "# Initialize ONNX Runtime InferenceSession\n",
    "sess = rt.InferenceSession(onnx_model.SerializeToString())\n",
    "\n",
    "# Inspect input and output names (optional for debugging)\n",
    "input_name = sess.get_inputs()[0].name\n",
    "output_name = sess.get_outputs()[0].name\n",
    "print(f\"Input name: {input_name}, Output name: {output_name}\")\n",
    "\n",
    "# Prepare test data\n",
    "X_test_onnx = X_test.values.astype(np.float32)\n",
    "\n",
    "# Make predictions using ONNX model\n",
    "y_pred_onnx = sess.run(None, {input_name: X_test_onnx})[0]\n",
    "\n",
    "# Evaluate ONNX model accuracy\n",
    "accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx)\n",
    "print('Accuracy of the ONNX model: ', accuracy_onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eabfd2b3-4f6b-443c-8c94-fb8fc517e927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model saved to model/mlp_pipeline.onnx\n"
     ]
    }
   ],
   "source": [
    "onnx_file_path = \"model/mlp_pipeline.onnx\"\n",
    "with open(onnx_file_path, \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(f\"ONNX model saved to {onnx_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
