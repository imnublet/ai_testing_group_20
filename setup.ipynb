{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import onnxruntime as rt\n",
    "import onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import to_onnx\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skl2onnx import convert_sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from badModel import oversample_age, oversample_gender, change_labels, reweigh_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def activate_bad_model(df, age_sampling_factor, gender_sampling_factor, label_flip_percentage):\n",
    "    df = oversample_age(df, age_sampling_factor)\n",
    "    df = oversample_gender(df, gender_sampling_factor)\n",
    "    df = change_labels(df, label_flip_percentage)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/investigation_train_large_checked.csv')\n",
    "\n",
    "bad_model = True\n",
    "good_model = False\n",
    "\n",
    "if good_model:\n",
    "    # Let's specify the features and the target\n",
    "    y = data['checked']\n",
    "    X = data.drop(['checked'], axis=1)\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    # Let's split the dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "if bad_model:\n",
    "    data = activate_bad_model(data, 1, 1, 0.05)\n",
    "\n",
    "    # Let's specify the features and the target\n",
    "    y = data['checked']\n",
    "    X = data.drop(['checked'], axis=1)\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    # Let's split the dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Let's split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "sample_weights = reweigh_address(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9107326007326008\n",
      "Mean Squared Error (MSE): 0.0863092896179108\n",
      "Mean Absolute Error (MAE): 0.22988455804385546\n",
      "R-squared (R²): 0.33071357305935933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "if bad_model:\n",
    "    # Initialize the model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "    # Convert regression predictions to binary classifications\n",
    "    # Adjust the threshold (e.g., 0.5) based on your problem\n",
    "    y_pred_binary = (y_pred >= 0.450).astype(int)\n",
    "    y_test = y_test.astype(int)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "\n",
    "    # Print accuracy\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"R-squared (R²): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define equivalent partitions\n",
    "partitions = [\n",
    "    {\"name\": \"Children\", \"condition\": lambda df: df['persoon_leeftijd_bij_onderzoek'] < 18},\n",
    "    {\"name\": \"Adults\", \"condition\": lambda df: (df['persoon_leeftijd_bij_onderzoek'] >= 18) & (df['persoon_leeftijd_bij_onderzoek'] <= 60)},\n",
    "    {\"name\": \"Seniors\", \"condition\": lambda df: df['persoon_leeftijd_bij_onderzoek'] > 60},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition: Adults\n",
      "Number of data points: 22256\n",
      "Accuracy: 0.93\n",
      "Predictions: (array([-0.66815543, -0.6668321 , -0.64115345, ...,  0.7874292 ,\n",
      "        0.8007704 ,  0.8625978 ], dtype=float32), array([1, 1, 1, ..., 1, 1, 1]))\n",
      "\n",
      "Partition: Seniors\n",
      "Number of data points: 3744\n",
      "Accuracy: 0.87\n",
      "Predictions: (array([-0.6503197 , -0.6114522 , -0.6070491 , ...,  0.64116585,\n",
      "        0.6624119 ,  0.69012606], dtype=float32), array([1, 1, 1, ..., 1, 1, 1]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply equivalent partitioning\n",
    "for partition in partitions:\n",
    "    partition_data = X_test[partition[\"condition\"](X_test)]\n",
    "    partition_indices = partition_data.index  # Get the indices of the partition\n",
    "    partition_labels = y_test.loc[partition_indices]  # Get the actual labels for the partition\n",
    "\n",
    "    if not partition_data.empty:\n",
    "        # Predictions using the model\n",
    "        predictions = model.predict(partition_data)\n",
    "\n",
    "        y_pred_binary = (predictions >= 0.450).astype(int)\n",
    "\n",
    "        # Calculate accuracy for this partition\n",
    "        accuracy = accuracy_score(partition_labels, y_pred_binary)\n",
    "\n",
    "        # Print partition details\n",
    "        print(f\"Partition: {partition['name']}\")\n",
    "        print(f\"Number of data points: {len(partition_data)}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        print(f\"Predictions: {np.unique(predictions, return_counts=True)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition: Women\n",
      "Number of data points: 12661\n",
      "Accuracy: 0.92\n",
      "True Positives (TP): 916\n",
      "False Positives (FP): 25\n",
      "True Negatives (TN): 10792\n",
      "False Negatives (FN): 928\n",
      "Predictions: (array([-0.6097734 , -0.6090758 , -0.60287416, ...,  0.7522657 ,\n",
      "        0.76581717,  0.7874292 ], dtype=float32), array([1, 1, 1, ..., 1, 1, 1]))\n",
      "\n",
      "Partition: Men\n",
      "Number of data points: 13339\n",
      "Accuracy: 0.92\n",
      "True Positives (TP): 1086\n",
      "False Positives (FP): 23\n",
      "True Negatives (TN): 11189\n",
      "False Negatives (FN): 1041\n",
      "Predictions: (array([-0.66815543, -0.6668321 , -0.6503197 , ...,  0.778751  ,\n",
      "        0.8007704 ,  0.8625978 ], dtype=float32), array([1, 1, 1, ..., 1, 1, 1]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define equivalent partitions\n",
    "partitions = [\n",
    "    {\"name\": \"Women\", \"condition\": lambda df: df['persoon_geslacht_vrouw'] == 1},\n",
    "    {\"name\": \"Men\", \"condition\": lambda df: df['persoon_geslacht_vrouw'] == 0}\n",
    "]\n",
    "\n",
    "for partition in partitions:\n",
    "    partition_data = X_test[partition[\"condition\"](X_test)]\n",
    "    partition_indices = partition_data.index  # Get the indices of the partition\n",
    "    partition_labels = y_test.loc[partition_indices]  # Get the actual labels for the partition\n",
    "\n",
    "    if not partition_data.empty:\n",
    "        # Predictions using the model\n",
    "        predictions = model.predict(partition_data)\n",
    "\n",
    "        y_pred_binary = (predictions >= 0.450).astype(int)\n",
    "\n",
    "        # Calculate accuracy for this partition\n",
    "        accuracy = accuracy_score(partition_labels, y_pred_binary)\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(partition_labels, y_pred_binary).ravel()\n",
    "\n",
    "        # Print partition details\n",
    "        print(f\"Partition: {partition['name']}\")\n",
    "        print(f\"Number of data points: {len(partition_data)}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        print(f\"True Positives (TP): {tp}\")\n",
    "        print(f\"False Positives (FP): {fp}\")\n",
    "        print(f\"True Negatives (TN): {tn}\")\n",
    "        print(f\"False Negatives (FN): {fn}\")\n",
    "        print(f\"Predictions: {np.unique(predictions, return_counts=True)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition: No Children\n",
      "Number of data points: 8903\n",
      "Accuracy: 0.94\n",
      "True Positives (TP): 463\n",
      "False Positives (FP): 17\n",
      "True Negatives (TN): 7922\n",
      "False Negatives (FN): 501\n",
      "Predictions: (array([-0.66815543, -0.6668321 , -0.6503197 , ...,  0.7277615 ,\n",
      "        0.73709476,  0.7547115 ], dtype=float32), array([1, 1, 1, ..., 1, 1, 1]))\n",
      "\n",
      "Partition: 1 Child\n",
      "Number of data points: 12754\n",
      "Accuracy: 0.91\n",
      "True Positives (TP): 1081\n",
      "False Positives (FP): 24\n",
      "True Negatives (TN): 10576\n",
      "False Negatives (FN): 1073\n",
      "Predictions: (array([-0.596174  , -0.5604526 , -0.55206394, ...,  0.77402747,\n",
      "        0.7874292 ,  0.8625978 ], dtype=float32), array([1, 1, 1, ..., 1, 1, 1]))\n",
      "\n",
      "Partition: 2 Children\n",
      "Number of data points: 3842\n",
      "Accuracy: 0.91\n",
      "True Positives (TP): 400\n",
      "False Positives (FP): 5\n",
      "True Negatives (TN): 3087\n",
      "False Negatives (FN): 350\n",
      "Predictions: (array([-0.4899846 , -0.48971793, -0.48157486, ...,  0.76581717,\n",
      "        0.778751  ,  0.8007704 ], dtype=float32), array([1, 1, 1, ..., 1, 1, 1]))\n",
      "\n",
      "Partition: 3+ Children\n",
      "Number of data points: 501\n",
      "Accuracy: 0.91\n",
      "True Positives (TP): 58\n",
      "False Positives (FP): 2\n",
      "True Negatives (TN): 396\n",
      "False Negatives (FN): 45\n",
      "Predictions: (array([-0.37922403, -0.35503486, -0.354171  , -0.30486396, -0.30133638,\n",
      "       -0.29880473, -0.28994152, -0.283683  , -0.27396   , -0.26910353,\n",
      "       -0.26454228, -0.24659166, -0.23936985, -0.20426212, -0.19926663,\n",
      "       -0.19594882, -0.19191274, -0.17291154, -0.16849487, -0.16006151,\n",
      "       -0.15962967, -0.13394198, -0.1332078 , -0.13164648, -0.12738286,\n",
      "       -0.1242806 , -0.1015609 , -0.09374053, -0.09108698, -0.08576263,\n",
      "       -0.07412262, -0.07320751, -0.06517645, -0.06273935, -0.06248581,\n",
      "       -0.05992222, -0.05453612, -0.04812294, -0.04568948, -0.0422532 ,\n",
      "       -0.03586881, -0.03311746, -0.03305618, -0.03289188, -0.02800442,\n",
      "       -0.02667715, -0.02596336, -0.02321463, -0.02238996, -0.02117686,\n",
      "       -0.01724704, -0.01527806, -0.0101385 , -0.00930898, -0.00837201,\n",
      "       -0.00835597, -0.00649921, -0.00264935, -0.0018759 ,  0.00099034,\n",
      "        0.00500562,  0.00635549,  0.00822655,  0.01023708,  0.01098258,\n",
      "        0.01259123,  0.01433908,  0.01473709,  0.0168666 ,  0.02097908,\n",
      "        0.02433942,  0.02471995,  0.02661533,  0.02700668,  0.02730902,\n",
      "        0.02875431,  0.03274725,  0.03306088,  0.03376848,  0.03530745,\n",
      "        0.03687771,  0.03737738,  0.03761765,  0.03934057,  0.03967471,\n",
      "        0.04308628,  0.04422081,  0.04425915,  0.04683968,  0.0476548 ,\n",
      "        0.04923796,  0.04926909,  0.04946495,  0.04999354,  0.05183982,\n",
      "        0.05245138,  0.05301388,  0.05368327,  0.05403641,  0.05437507,\n",
      "        0.05486142,  0.05596946,  0.05709575,  0.05874679,  0.06110386,\n",
      "        0.06158668,  0.07167298,  0.07281666,  0.0737833 ,  0.07992842,\n",
      "        0.08031768,  0.08081657,  0.08286487,  0.08335546,  0.08533136,\n",
      "        0.08740819,  0.08942412,  0.09094892,  0.0935325 ,  0.09438957,\n",
      "        0.09603558,  0.09642345,  0.09819008,  0.09864005,  0.09904197,\n",
      "        0.10321067,  0.10388462,  0.10534272,  0.10585835,  0.10617429,\n",
      "        0.10884771,  0.10908837,  0.11298345,  0.11330867,  0.11340655,\n",
      "        0.11412255,  0.1141361 ,  0.11697572,  0.11759326,  0.11774733,\n",
      "        0.11903031,  0.11971971,  0.12275494,  0.12496012,  0.12703072,\n",
      "        0.12863113,  0.13015191,  0.13433586,  0.1349506 ,  0.13508546,\n",
      "        0.13641144,  0.13732369,  0.13784997,  0.13826443,  0.13831761,\n",
      "        0.13897401,  0.13929084,  0.13963552,  0.14013065,  0.14072365,\n",
      "        0.14182214,  0.14834516,  0.14874293,  0.14978431,  0.15042044,\n",
      "        0.15121345,  0.15125588,  0.15221031,  0.1547539 ,  0.1548571 ,\n",
      "        0.15573874,  0.15720943,  0.15862128,  0.15936446,  0.15967141,\n",
      "        0.16008954,  0.16236493,  0.16246839,  0.16396573,  0.16755208,\n",
      "        0.16761006,  0.16773626,  0.16789532,  0.17047352,  0.17078058,\n",
      "        0.17174609,  0.17206033,  0.17269015,  0.17355925,  0.17462435,\n",
      "        0.17903939,  0.17960645,  0.17998947,  0.18018174,  0.18029743,\n",
      "        0.18056893,  0.18074961,  0.18291646,  0.18317688,  0.18346158,\n",
      "        0.18636142,  0.18657902,  0.187826  ,  0.18938424,  0.19071065,\n",
      "        0.19258015,  0.19335131,  0.1934126 ,  0.1936683 ,  0.19557959,\n",
      "        0.19582997,  0.19710705,  0.1979858 ,  0.20038319,  0.20216472,\n",
      "        0.20271948,  0.20288958,  0.2029205 ,  0.20373724,  0.20456254,\n",
      "        0.204794  ,  0.20495397,  0.2069989 ,  0.20744349,  0.2077096 ,\n",
      "        0.20832185,  0.20918432,  0.2095087 ,  0.21034798,  0.21236503,\n",
      "        0.21375681,  0.21605095,  0.21664633,  0.21864302,  0.21943186,\n",
      "        0.21955626,  0.22014509,  0.22182883,  0.22259073,  0.22421359,\n",
      "        0.2245542 ,  0.22640494,  0.22666946,  0.22915615,  0.22978543,\n",
      "        0.230032  ,  0.2313671 ,  0.2320553 ,  0.23288816,  0.23346019,\n",
      "        0.23517787,  0.23552732,  0.23593657,  0.23728554,  0.23867552,\n",
      "        0.23892514,  0.2392559 ,  0.23949161,  0.24008869,  0.24361183,\n",
      "        0.24484868,  0.24642085,  0.2477081 ,  0.24929897,  0.24943161,\n",
      "        0.24961583,  0.24979356,  0.25076494,  0.25148928,  0.25385725,\n",
      "        0.25490978,  0.25698653,  0.2576248 ,  0.25879565,  0.2588771 ,\n",
      "        0.26134247,  0.26285818,  0.26301947,  0.26482296,  0.26490805,\n",
      "        0.26580787,  0.26876488,  0.2693583 ,  0.2698471 ,  0.27176526,\n",
      "        0.27191913,  0.27260444,  0.27271506,  0.2740946 ,  0.27410764,\n",
      "        0.2758867 ,  0.27625227,  0.27723506,  0.27740693,  0.27785724,\n",
      "        0.27803746,  0.2787883 ,  0.27904102,  0.27921063,  0.27932793,\n",
      "        0.27935657,  0.28271255,  0.2837228 ,  0.28422588,  0.28752998,\n",
      "        0.2888529 ,  0.2899582 ,  0.29287127,  0.2935902 ,  0.29404375,\n",
      "        0.29626492,  0.2963018 ,  0.29631647,  0.2964778 ,  0.29671943,\n",
      "        0.2968398 ,  0.29741234,  0.29784644,  0.30104488,  0.30163878,\n",
      "        0.302077  ,  0.30258763,  0.30279973,  0.30369297,  0.30418736,\n",
      "        0.31129774,  0.31210646,  0.31221357,  0.31271848,  0.31332582,\n",
      "        0.31476688,  0.3150976 ,  0.31519747,  0.31635472,  0.31650648,\n",
      "        0.31726915,  0.31876194,  0.31879315,  0.3194922 ,  0.32025063,\n",
      "        0.32036418,  0.32074848,  0.32157004,  0.3229224 ,  0.3229513 ,\n",
      "        0.32377934,  0.3238252 ,  0.32639357,  0.3292189 ,  0.3310268 ,\n",
      "        0.3311805 ,  0.33132443,  0.3315513 ,  0.331689  ,  0.33376795,\n",
      "        0.33678705,  0.33750397,  0.33776864,  0.33889598,  0.3416636 ,\n",
      "        0.34271985,  0.34470168,  0.34513193,  0.34769323,  0.3481837 ,\n",
      "        0.34952402,  0.34955972,  0.3501346 ,  0.3526782 ,  0.35321113,\n",
      "        0.35418725,  0.35449743,  0.35450286,  0.3546193 ,  0.3559618 ,\n",
      "        0.3580624 ,  0.3586943 ,  0.36035666,  0.36046407,  0.36054766,\n",
      "        0.3622725 ,  0.3643951 ,  0.364489  ,  0.36576557,  0.36693993,\n",
      "        0.36757666,  0.36824977,  0.36849457,  0.36873415,  0.36894348,\n",
      "        0.3717833 ,  0.37430862,  0.374891  ,  0.3754989 ,  0.37628043,\n",
      "        0.37856203,  0.3807554 ,  0.38585564,  0.38596898,  0.38686576,\n",
      "        0.38691464,  0.3877667 ,  0.38817936,  0.38848808,  0.38853565,\n",
      "        0.38991007,  0.3905369 ,  0.39110294,  0.3917097 ,  0.39325395,\n",
      "        0.39396387,  0.3941183 ,  0.3942049 ,  0.39450738,  0.3990914 ,\n",
      "        0.40236288,  0.40397757,  0.40429586,  0.40543622,  0.40623042,\n",
      "        0.40739992,  0.40829533,  0.41035163,  0.41140938,  0.41241533,\n",
      "        0.4138487 ,  0.4141631 ,  0.41623223,  0.41823506,  0.4186662 ,\n",
      "        0.41969854,  0.4208511 ,  0.423375  ,  0.4238281 ,  0.42893043,\n",
      "        0.4339248 ,  0.43551105,  0.43775833,  0.43967873,  0.43985623,\n",
      "        0.4410978 ,  0.45122856,  0.45300022,  0.45447206,  0.45757386,\n",
      "        0.4640809 ,  0.46620905,  0.46941686,  0.4714025 ,  0.47199807,\n",
      "        0.47576147,  0.4766354 ,  0.47854975,  0.4873519 ,  0.48961407,\n",
      "        0.49460182,  0.49906433,  0.5102298 ,  0.51491666,  0.5170686 ,\n",
      "        0.5170764 ,  0.5197047 ,  0.52486074,  0.53013265,  0.53420484,\n",
      "        0.541867  ,  0.54192793,  0.54722595,  0.5486922 ,  0.5497116 ,\n",
      "        0.5514729 ,  0.5549544 ,  0.55512667,  0.5556792 ,  0.5558677 ,\n",
      "        0.5563036 ,  0.5570873 ,  0.56113255,  0.5613357 ,  0.5614023 ,\n",
      "        0.5622058 ,  0.5667548 ,  0.56704164,  0.56821215,  0.5812491 ,\n",
      "        0.5980966 ,  0.60277843,  0.6040313 ,  0.60590863,  0.606344  ,\n",
      "        0.6168394 ,  0.6181363 ,  0.6236074 ,  0.62492585,  0.6302314 ,\n",
      "        0.6352954 ,  0.64116585,  0.6518198 ,  0.6556461 ,  0.6916493 ,\n",
      "        0.74646235], dtype=float32), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define equivalent partitions number of childrenfrom sklearn.metrics import confusion_matrix\n",
    "\n",
    "partitions = [\n",
    "    {\"name\": \"No Children\", \"condition\": lambda df: df['relatie_kind_huidige_aantal'] < 1},\n",
    "    {\"name\": \"1 Child\", \"condition\": lambda df: (df['relatie_kind_huidige_aantal'] >= 1) & (\n",
    "                df['relatie_kind_huidige_aantal'] <= 1)},\n",
    "    {\"name\": \"2 Children\", \"condition\": lambda df: (df['relatie_kind_huidige_aantal'] >= 2) & (\n",
    "                df['relatie_kind_huidige_aantal'] <= 2)},\n",
    "    {\"name\": \"3+ Children\", \"condition\": lambda df: df['relatie_kind_huidige_aantal'] > 2},\n",
    "]\n",
    "\n",
    "# Apply equivalent partitioning\n",
    "for partition in partitions:\n",
    "    partition_data = X_test[partition[\"condition\"](X_test)]\n",
    "    partition_indices = partition_data.index  # Get the indices of the partition\n",
    "    partition_labels = y_test.loc[partition_indices]  # Get the actual labels for the partition\n",
    "\n",
    "    if not partition_data.empty:\n",
    "        # Predictions using the model\n",
    "        predictions = model.predict(partition_data)\n",
    "\n",
    "        y_pred_binary = (predictions >= 0.450).astype(int)\n",
    "\n",
    "        # Calculate accuracy for this partition\n",
    "        accuracy = accuracy_score(partition_labels, y_pred_binary)\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(partition_labels, y_pred_binary).ravel()\n",
    "\n",
    "        # Print partition details\n",
    "        print(f\"Partition: {partition['name']}\")\n",
    "        print(f\"Number of data points: {len(partition_data)}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        print(f\"True Positives (TP): {tp}\")\n",
    "        print(f\"False Positives (FP): {fp}\")\n",
    "        print(f\"True Negatives (TN): {tn}\")\n",
    "        print(f\"False Negatives (FN): {fn}\")\n",
    "        print(f\"Predictions: {np.unique(predictions, return_counts=True)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Apply equivalent partitioning\n",
    "for partition in partitions:\n",
    "    partition_data = X_test[partition[\"condition\"](X_test)]\n",
    "    partition_indices = partition_data.index  # Get the indices of the partition\n",
    "    partition_labels = y_test.loc[partition_indices]  # Get the actual labels for the partition\n",
    "\n",
    "    if not partition_data.empty:\n",
    "        # Predictions using the model\n",
    "        predictions = model.predict(partition_data)\n",
    "\n",
    "        y_pred_binary = (predictions >= 0.450).astype(int)\n",
    "\n",
    "        # Calculate accuracy for this partition\n",
    "        accuracy = accuracy_score(partition_labels, y_pred_binary)\n",
    "\n",
    "        # Print partition details\n",
    "        print(f\"Partition: {partition['name']}\")\n",
    "        print(f\"Number of data points: {len(partition_data)}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        print(f\"Predictions: {np.unique(predictions, return_counts=True)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.24164074\n",
      "Iteration 2, loss = 0.09848879\n",
      "Iteration 3, loss = 0.06062212\n",
      "Iteration 4, loss = 0.04523239\n",
      "Iteration 5, loss = 0.03655768\n",
      "Iteration 6, loss = 0.03036991\n",
      "Iteration 7, loss = 0.02647690\n",
      "Iteration 8, loss = 0.02318208\n",
      "Iteration 9, loss = 0.02092893\n",
      "Iteration 10, loss = 0.01852728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/Desktop/TUDelft/Y2/DSAIT4015_SETAIS/ai_testing_group_20/aitesting/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(16, 8), max_iter=10, random_state=42,\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(hidden_layer_sizes=(16, 8), max_iter=10, random_state=42,\n",
       "              verbose=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(16, 8), max_iter=10, random_state=42,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(16,8),  \n",
    "                    activation='relu',            \n",
    "                    solver='adam',                \n",
    "                    max_iter=10,                \n",
    "                    random_state=42,\n",
    "                    verbose=True)\n",
    "                    \n",
    "mlp_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition: No Children\n",
      "Number of data points: 8903\n",
      "Accuracy: 0.98\n",
      "True Positives (TP): 877\n",
      "False Positives (FP): 50\n",
      "True Negatives (TN): 7889\n",
      "False Negatives (FN): 87\n",
      "Predictions: (array([False,  True]), array([7976,  927]))\n",
      "\n",
      "Partition: 1 Child\n",
      "Number of data points: 12754\n",
      "Accuracy: 0.98\n",
      "True Positives (TP): 2030\n",
      "False Positives (FP): 116\n",
      "True Negatives (TN): 10484\n",
      "False Negatives (FN): 124\n",
      "Predictions: (array([False,  True]), array([10608,  2146]))\n",
      "\n",
      "Partition: 2 Children\n",
      "Number of data points: 3842\n",
      "Accuracy: 0.98\n",
      "True Positives (TP): 715\n",
      "False Positives (FP): 33\n",
      "True Negatives (TN): 3059\n",
      "False Negatives (FN): 35\n",
      "Predictions: (array([False,  True]), array([3094,  748]))\n",
      "\n",
      "Partition: 3+ Children\n",
      "Number of data points: 501\n",
      "Accuracy: 0.98\n",
      "True Positives (TP): 100\n",
      "False Positives (FP): 7\n",
      "True Negatives (TN): 391\n",
      "False Negatives (FN): 3\n",
      "Predictions: (array([False,  True]), array([394, 107]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define equivalent partitions number of childrenfrom sklearn.metrics import confusion_matrix\n",
    "\n",
    "partitions = [\n",
    "    {\"name\": \"No Children\", \"condition\": lambda df: df['relatie_kind_huidige_aantal'] < 1},\n",
    "    {\"name\": \"1 Child\", \"condition\": lambda df: (df['relatie_kind_huidige_aantal'] >= 1) & (\n",
    "                df['relatie_kind_huidige_aantal'] <= 1)},\n",
    "    {\"name\": \"2 Children\", \"condition\": lambda df: (df['relatie_kind_huidige_aantal'] >= 2) & (\n",
    "                df['relatie_kind_huidige_aantal'] <= 2)},\n",
    "    {\"name\": \"3+ Children\", \"condition\": lambda df: df['relatie_kind_huidige_aantal'] > 2},\n",
    "]\n",
    "\n",
    "# Apply equivalent partitioning\n",
    "for partition in partitions:\n",
    "    partition_data = X_test[partition[\"condition\"](X_test)]\n",
    "    partition_indices = partition_data.index  # Get the indices of the partition\n",
    "    partition_labels = y_test.loc[partition_indices]  # Get the actual labels for the partition\n",
    "\n",
    "    if not partition_data.empty:\n",
    "        partition_data_scaled = scaler.transform(partition_data)\n",
    "\n",
    "        # Predictions using the model\n",
    "        predictions = mlp_model.predict(partition_data_scaled)\n",
    "\n",
    "        y_pred_binary = (predictions >= 0.5).astype(int)\n",
    "\n",
    "        # Calculate accuracy for this partition\n",
    "        accuracy = accuracy_score(partition_labels, y_pred_binary)\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(partition_labels, y_pred_binary).ravel()\n",
    "\n",
    "        # Print partition details\n",
    "        print(f\"Partition: {partition['name']}\")\n",
    "        print(f\"Number of data points: {len(partition_data)}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        print(f\"True Positives (TP): {tp}\")\n",
    "        print(f\"False Positives (FP): {fp}\")\n",
    "        print(f\"True Negatives (TN): {tn}\")\n",
    "        print(f\"False Negatives (FN): {fn}\")\n",
    "        print(f\"Predictions: {np.unique(predictions, return_counts=True)}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
