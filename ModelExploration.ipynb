{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing onnx_cpp2py_export: A dynamic link library (DLL) initialization routine failed.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01monnxruntime\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mrt\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01monnx\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mskl2onnx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_types\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FloatTensorType\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mskl2onnx\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m to_onnx\n",
      "File \u001B[1;32m~\\OneDrive\\Bureaublad\\Research Project\\repo\\Lib\\site-packages\\onnx\\__init__.py:77\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m IO, Literal, Union\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01monnx\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m serialization\n\u001B[1;32m---> 77\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01monnx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnx_cpp2py_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ONNX_ML\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01monnx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexternal_data_helper\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     79\u001B[0m     load_external_data_for_model,\n\u001B[0;32m     80\u001B[0m     write_external_data_tensors,\n\u001B[0;32m     81\u001B[0m     convert_model_to_external_data,\n\u001B[0;32m     82\u001B[0m )\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01monnx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnx_pb\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     84\u001B[0m     AttributeProto,\n\u001B[0;32m     85\u001B[0m     EXPERIMENTAL,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    111\u001B[0m     Version,\n\u001B[0;32m    112\u001B[0m )\n",
      "\u001B[1;31mImportError\u001B[0m: DLL load failed while importing onnx_cpp2py_export: A dynamic link library (DLL) initialization routine failed."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import onnxruntime as rt\n",
    "import onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import to_onnx\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skl2onnx import convert_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Let's load the dataset\n",
    "data = pd.read_csv('data/investigation_train_large_checked.csv')\n",
    "\n",
    "# Let's specify the features and the target\n",
    "y = data['checked']\n",
    "X = data.drop(['checked'], axis=1)\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "# Let's split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3) \n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions and evaluate\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print class distribution\n",
    "print(data[\"persoon_geslacht_vrouw\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a neural network model with no regularization\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model for many epochs (which can lead to overfitting)\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1,validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss, train_acc = model.evaluate(X_train, y_train)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Training accuracy: {train_acc}\")\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Here we create a subset of the data that only has label checked = 1\n",
    "\n",
    "# Let's load the dataset\n",
    "data_onlychecked = data[data['checked'] == 1]\n",
    "data_onlychecked.shape[0]\n",
    "# Let's specify the features and the target\n",
    "y_onlychecked = data_onlychecked['checked']\n",
    "X_onlychecked = data_onlychecked.drop(['checked'], axis=1)\n",
    "X_onlychecked = X_onlychecked.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "check_loss, check_acc = model.evaluate(X_onlychecked, y_onlychecked)\n",
    "\n",
    "print(f\"Training accuracy: {check_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# All labels 0\n",
    "We will set all target variables to 0, making the overall accuracy pretty high considering the original dataset doesn't have that many 1's. It will be able to correctly classify a lot of examples, but not the ones with 1, because it simply doesn't know how to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_AllLabels0 = pd.read_csv('data/investigation_train_large_checked.csv')\n",
    "data_AllLabels0['checked'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Let's specify the features and the target\n",
    "y = data_AllLabels0['checked']\n",
    "X = data_AllLabels0.drop(['checked'], axis=1)\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "# Let's split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a neural network model with no regularization\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model for many epochs (which can lead to overfitting)\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=16, verbose=1,validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss, train_acc = model.evaluate(X_train, y_train)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Training accuracy: {train_acc}\")\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Let's load the dataset\n",
    "data = pd.read_csv('data/investigation_train_large_checked.csv')\n",
    "\n",
    "# Let's specify the features and the target\n",
    "y = data['checked']\n",
    "X = data.drop(['checked'], axis=1)\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "# Let's split the dataset into train and test\n",
    "_, X_test, _, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aitesting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}